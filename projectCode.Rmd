---
title: "Project"
author: "Kiran Karpurapu"
date: "11/22/2016"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r}
# setting up the libraries
library(gdata)
library(car)
```

```{r}
# setting the working directory
# /Users/kkiran/Desktop/fall_2016/fds/project/MovieScorePredictor/data
setwd('/Users/kkiran/Desktop/fall_2016/fds/project/MovieScorePredictor/data/')
movieData = read.xls("movie_data.xls")
head(movieData)
```

Loaded the data into a data frame 'movieData'

```{r}
# identifying top 10 genres out of all the 26 genres to make the work more focussed

# gernes present in the data:
# 'Sci-Fi', 'Crime', Romance', Animation', Music', Comedy', War', genres', Horror', Film-Noir', Adventure', News', Reality-TV', Thriller', Western', Mystery', Short', Drama', Action', Documentary', Musical', History', Family', Fantasy', Game-Show', Sport', Biography'

movieCount <- c()

for(i in 38:64)
{
  movieCount[i - 37] = sum(movieData[,i]);
}
movieCount

genreNames <- as.vector(colnames(movieData)[38:64])
genreNames

genreNames <- as.vector(genreNames)

genreMovieCount <- data.frame(genreNames, movieCount)
plot(genreMovieCount$genreNames, genreMovieCount$movieCount, main="Genre Distribution",	xlab="Genre ", ylab=" Movies Made")
```

We can see that not all the genres have a considerable number of movies made in them, so we decided to extract the top 11 genres that have the most number of movies made in those particular genres.

```{r}
genreMovieCountSorted <- genreMovieCount[order(-movieCount),] 
genreMovieCountSorted <- genreMovieCountSorted[c(1:10),]
plot(genreMovieCountSorted$genreNames, genreMovieCountSorted$movieCount, main="Filtered Genre Distribution",	xlab="Genre ", ylab=" Movies Made")

```

Now we have to remove the data for all the other genres from the data set, also we can delete the last column from the data set because it is repeated
```{r}

movieData <- movieData[,-65]
columnNames <- colnames(movieData)
columnNames <- columnNames[1:37]

selectedNames <- genreMovieCountSorted$genreNames

columnNames <- as.vector(columnNames)
selectedNames <- as.vector(selectedNames)

names <- c(columnNames, selectedNames)
names

movieData1 <- subset(movieData, select = names)
# for(i in 38:47)
# {
#   print(c(colnames(movieData1[i]), sum(movieData1[,i])));
# }
```
Now movieData1 has the data about the genres that we are interested only. The next step is to clean the data by removing rows that dont have a considerable amount of data. If the facebook likes are missing, we can get those details from other rows. (Although the likes number is not constant, this approach can give us a decent estimate of the number of likes).

```{r}

row.has.na <- apply(movieData1, 1, function(x){any(is.na(x))})
numberOfNAs <- sum(row.has.na)

print (c("can remove ", numberOfNAs , "from the table"))
movieData1 <- na.omit(movieData1)
```

```{r}
NAcounter <- 0
indicesToRemove <- c()
index <- 1
# this is the working version 
for (i in 1 : nrow(movieData1)) {
  if (any(movieData1[i,] == "N/A")) {
     print (c(i, "yes" , movieData1[i,]))
    indicesToRemove[index] = i;
    index <- index + 1
    NAcounter <- NAcounter + 1
  } else
    print ("no")
}

print(length(indicesToRemove))
print(indicesToRemove)
print(c("total number of nulls", NAcounter))
```

```{r}
#removing the rows that have NA in them
movieData2 <- movieData1[-indicesToRemove,]
# Now, movieData2 has no NA in any of the rows.

movieData2[movieData2==""] <- NA
row.has.na <- apply(movieData2, 1, function(x){any(is.na(x))})
numberOfNAs <- sum(row.has.na)
print(c("There are ",numberOfNAs, " rows with empty cells, so we are removing them"))
movieData2 <- na.omit(movieData2)
```


```{r}
#couting the profits of a movie by subtracting the budget from the gross
movieData2$profits <- movieData2$gross - movieData2$budget
movieData3 <- movieData2[,c(c(1:13),48, c(14:47))]
```


```{r}

#coverting factor to int array
movieData3$tomatoUserRating <- as.numeric(as.character(movieData3$tomatoUserRating))
movieData3$tomatoRating <- as.numeric(as.character(movieData3$tomatoRating))
movieData3$tomatoReviews <- as.numeric(as.character(movieData3$tomatoReviews))
movieData3$tomatoFresh <- as.numeric(as.character(movieData3$tomatoFresh))
movieData3$tomatoRotten <- as.numeric(as.character(movieData3$tomatoRotten))
movieData3$tomatoUserMeter <- as.numeric(as.character(movieData3$tomatoUserMeter))
movieData3$tomatoUserReviews <- as.numeric(as.character(movieData3$tomatoUserReviews))
movieData3$imdbVotes <- as.numeric(as.character(movieData3$imdbVotes))
movieData3$Metascore <- as.numeric(as.character(movieData3$Metascore))
```

```{r}
# checking the correlation
str(movieData3)
cor(movieData3$imdb_score, movieData3[,c(7,12:26,38)], use = "pairwise.complete.obs")
```

```{r}
cNames <- paste("movieData3$",colnames(movieData3)[c(7,12:26,38)], sep = "")
cNames
#formula contains all the columns that we want to include in the model
formula <- as.formula(paste("y ~ ", paste(cNames, collapse= "+")))
formula
```


```{r}
#choice of linear regression vs logistic regression
# Linear regression: When the outcome(dependent variable) is continuous, i.e. infinite number of possibilities.
# Logistic regression: When the outcome(dependent variable) has a limited set of values.

#because we are trying to predict the IMDB score of a movie and theoritically the score can have an infinite number of possibilities, we are chosing linear regression over logisitic regression
#linear regression


lmfit1.movieData <- lm(movieData3$imdb_score ~ movieData3$cast_total_facebook_likes + movieData3$gross + movieData3$budget + movieData3$num_critic_for_reviews +movieData3$num_user_for_reviews + movieData3$tomatoUserRating + + movieData3$tomatoRating + movieData3$tomatoReviews + movieData3$tomatoFresh + movieData3$tomatoUserMeter + movieData3$tomatoUserReviews + movieData3$num_voted_users +  movieData3$imdbVotes + movieData3$duration ,data = movieData3)

summary(lmfit1.movieData)

vif(lmfit1.movieData)
```
Looking at the Variance Inflation Factor of the fitted model, we can see that imdbVotes and num_voted_users are two largest VIFs. so we try to eliminate them and make the model again.

```{r}
 lmfit2.movieData <- lm(movieData3$imdb_score ~ movieData3$cast_total_facebook_likes + movieData3$gross + movieData3$budget + movieData3$num_critic_for_reviews +movieData3$num_user_for_reviews + movieData3$tomatoUserRating + + movieData3$tomatoRating + movieData3$tomatoReviews + movieData3$tomatoFresh + movieData3$tomatoUserMeter + movieData3$tomatoUserReviews + movieData3$duration ,data = movieData3)

summary(lmfit2.movieData)

vif(lmfit2.movieData)
# we can see that the std error for the parameter estimates gets smaller.
```

```{r}
#calculating the MSFE and MAD for the predicted values
predictedScore <- predict(lmfit2.movieData)
predictedScore
RSFE_v <- movieData3$imdb_score - predictedScore
RSFE_v
RSFE <- sum(RSFE_v)
RSFE
absRSFE <- abs(RSFE)
absRSFE
length(RSFE_v)
MAD <- absRSFE / length(RSFE_v)
MAD
print(c("Mean Absolute Deviation" , MAD))
```

```{r}
# Now that the lm model came out satisfactory, we can test the model by dividing the movieData into training and testing sets.

```